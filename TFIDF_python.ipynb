{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "42344751-df85-4fa9-af08-b4bf50b41e05"
    }
   },
   "source": [
    "# Using $tfidf$ to identify context-important words  \n",
    "\n",
    "In this notebook we will go into the details of how to run $tfidf$ step by step in code. For the full background on this topic, please checkout the SandyEdge blog post here: <http://xxxx.com>.\n",
    "\n",
    "But before we begin, let me first introduce the mathematical equation, which I proudly spent the weekend learning the LaTex code for:\n",
    "\n",
    "$$ tfidf_{t,d} = tf_{t,d} \\cdot \\log \\frac{N}{df_t} $$\n",
    "<center>**_ where_ **<center>\n",
    "$t$ = _term_\n",
    "<br>\n",
    "$d$ = _document_\n",
    "<br>\n",
    "$ tfidf_{t,d}$ = _term $t$ $tfidf$ score for document_ $d$\n",
    "<br>\n",
    "$ tf_{t,d}$ = _number of occurences of term $t$ in document $d$_\n",
    "<br>\n",
    "$ {df_t}$ = _number of documents containing term $t$_\n",
    "<br>\n",
    "$ N $ = _total number of documents_\n",
    "\n",
    "So without further ado, lets begin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "6b931974-2fc8-4fdc-9f32-a93d21ec08ef"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd       \n",
    "import os \n",
    "import math \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "os.chdir(\"C:\\\\Users\\\\user\\\\Dropbox\\\\Pet Project\\\\Blog\\\\TFIDF\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to use my own dataset which is based on Student essays. You can easily find other datasets and examples, in the wild but I'm using this as it is one of the better datasets for text mining due to its large signal over noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Dear local newspaper, I think effects computers have on people are great learning skills/affects because they give us time to chat with friends/new people, helps us learn about the globe(astronomy) and keeps us out of troble! Thing about! Dont you think so? How would you feel if your teenager is always on the phone with friends! Do you ever time to chat with your friends or buisness partner about things. Well now - there\\'s a new way to chat the computer, theirs plenty of sites on the internet to do so: @ORGANIZATION1, @ORGANIZATION2, @CAPS1, facebook, myspace ect. Just think now while your setting up meeting with your boss on the computer, your teenager is having fun on the phone not rushing to get off cause you want to use it. How did you learn about other countrys/states outside of yours? Well I have by computer/internet, it\\'s a new way to learn about what going on in our time! You might think your child spends a lot of time on the computer, but ask them so question about the economy, sea floor spreading or even about the @DATE1\\'s you\\'ll be surprise at how much he/she knows. Believe it or not the computer is much interesting then in class all day reading out of books. If your child is home on your computer or at a local library, it\\'s better than being out with friends being fresh, or being perpressured to doing something they know isnt right. You might not know where your child is, @CAPS2 forbidde in a hospital bed because of a drive-by. Rather than your child on the computer learning, chatting or just playing games, safe and sound in your home or community place. Now I hope you have reached a point to understand and agree with me, because computers can have great effects on you or child because it gives us time to chat with friends/new people, helps us learn about the globe and believe or not keeps us out of troble. Thank you for listening.\"'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the data \n",
    "train = pd.read_csv(\"training_set.tsv\", header=0, delimiter=\"\\t\", quoting=3,encoding = 'latin_1')\n",
    "train = train[train.essay_set == 1]\n",
    "\n",
    "#do some checks\n",
    "train.shape\n",
    "train['essay'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "If you read through the above, the only issue with highschool essay's is that its filled with spelling mistakes. Now lets get the dataset into the proper object, and then we can start cleaning the text so we can apply $tfidf$\n",
    "\n",
    "Unlike the R version, Python has a very neat and quick way to transform the dataset straight into a DTM (document-term-matrix). DTM is basically a matrix of documents on rows and terms on columns. Its the native format that is required to also run SVD / LSI (Latent Semantic Indexing) and topic modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1783, 15735)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DTM of counts \n",
    "cvec = CountVectorizer()\n",
    "cvec_counts = cvec.fit_transform(train['essay'])\n",
    "\n",
    "# Check the dimensions of the DTM \n",
    "cvec_counts.shape  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "1,783 documents by 15,735 word vectors. Sounds about right. Can't say much about the 15k word vectors but 1,783 documents is definetly what we need. Note that the default parameter settings of CountVectorizer() will include 'lowercase application' and 'ignores punctuations'. Now lets find out what the word distribution is like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14246</th>\n",
       "      <td>22205</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13989</th>\n",
       "      <td>22200</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>18613</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15681</th>\n",
       "      <td>17907</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2844</th>\n",
       "      <td>10646</td>\n",
       "      <td>computers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9771</th>\n",
       "      <td>10406</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10286</th>\n",
       "      <td>10324</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13983</th>\n",
       "      <td>9878</td>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9697</th>\n",
       "      <td>9780</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>9259</td>\n",
       "      <td>computer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       frequency       term\n",
       "14246      22205         to\n",
       "13989      22200        the\n",
       "648        18613        and\n",
       "15681      17907        you\n",
       "2844       10646  computers\n",
       "9771       10406         on\n",
       "10286      10324     people\n",
       "13983       9878       that\n",
       "9697        9780         of\n",
       "2836        9259   computer"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # sum up all the counts for the word vector\n",
    "freq = np.asarray(cvec_counts.sum(axis=0)).ravel().tolist() \n",
    "counts_df = pd.DataFrame({'term': cvec.get_feature_names(), 'frequency': freq})\n",
    "\n",
    "# lets print the top 20 most frequent term \n",
    "counts_df.sort_values(by='frequency', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "Based on frequency counts, lots of stopwords and generic terms like \"computers\" are appearing. This is expected since we didn't do any stop words removal, or $tfidf$ for that matter. So in this part of the process, is essentially the Term Frequency (TF) component in $tfidf$. So now, lets apply the $tfidf$ full transfomation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3630)\t0.0205795178957\n",
      "  (0, 8375)\t0.0692567747786\n",
      "  (0, 9414)\t0.0296724820614\n",
      "  (0, 14086)\t0.0888150263924\n",
      "  (0, 4577)\t0.0855372612395\n",
      "  (0, 2844)\t0.0313049145955\n",
      "  (0, 6692)\t0.0637103482304\n",
      "  (0, 9771)\t0.151937023131\n",
      "  (0, 10286)\t0.0466419753712\n",
      "  (0, 833)\t0.0154516111753\n",
      "  (0, 6442)\t0.0650269796243\n",
      "  (0, 8137)\t0.0855372612395\n",
      "  (0, 12731)\t0.0522323088082\n",
      "  (0, 378)\t0.0665549003141\n",
      "  (0, 1304)\t0.0796254467089\n",
      "  (0, 14058)\t0.0334191217792\n",
      "  (0, 6259)\t0.0374067800391\n",
      "  (0, 14844)\t0.195749236724\n",
      "  (0, 14207)\t0.0993557830735\n",
      "  (0, 14246)\t0.147571248637\n",
      "  (0, 2313)\t0.145155526491\n",
      "  (0, 15454)\t0.113009335539\n",
      "  (0, 6028)\t0.104703215001\n",
      "  (0, 9397)\t0.132086034922\n",
      "  (0, 6798)\t0.080617181976\n",
      "  :\t:\n",
      "  (1782, 10225)\t0.0754486130427\n",
      "  (1782, 2121)\t0.0849473257093\n",
      "  (1782, 13986)\t0.130740365821\n",
      "  (1782, 6318)\t0.116169766347\n",
      "  (1782, 10744)\t0.083226699468\n",
      "  (1782, 10361)\t0.0827601959427\n",
      "  (1782, 8592)\t0.0659777931142\n",
      "  (1782, 8106)\t0.076445214015\n",
      "  (1782, 8604)\t0.112969824335\n",
      "  (1782, 13391)\t0.102967572392\n",
      "  (1782, 9751)\t0.102967572392\n",
      "  (1782, 549)\t0.138975346059\n",
      "  (1782, 8090)\t0.122925058063\n",
      "  (1782, 4633)\t0.135775404048\n",
      "  (1782, 839)\t0.0980926469344\n",
      "  (1782, 1627)\t0.142760074157\n",
      "  (1782, 664)\t0.128371355368\n",
      "  (1782, 5052)\t0.153364064848\n",
      "  (1782, 15685)\t0.138975346059\n",
      "  (1782, 3596)\t0.153364064848\n",
      "  (1782, 7090)\t0.161780925772\n",
      "  (1782, 13656)\t0.161780925772\n",
      "  (1782, 4483)\t0.161780925772\n",
      "  (1782, 1733)\t0.161780925772\n",
      "  (1782, 10385)\t0.161780925772\n"
     ]
    }
   ],
   "source": [
    "transformer = TfidfTransformer() \n",
    "transformed_weights = transformer.fit_transform(cvec_counts)  #this takes the previous Count Vector object above \n",
    "\n",
    "# Check the dimensions of the DTM \n",
    "transformed_weights.shape  \n",
    "\n",
    "#lets check out how the results look like\n",
    "print(transformed_weights) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "Noticed the numbers are now very different to the original cvec_counts above? Well this is because we've reweighted the DTM by $tfidf$ now. Or more specifically the words in each row is $tfidf$ weighted. For more detailed explanation of the formula and how it works, please read through the blog post on SandyEdge.\n",
    "\n",
    "So lets find out which word has the highest $tfidf$ score. Because $tfidf$ for each word is different for each document (row), so what we'll do is take the average $tfidf$ score for each word across all 1,783 documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py:214: SparseEfficiencyWarning: Comparing a sparse matrix with 0 using == is inefficient, try using != instead.\n",
      "  \", try using != instead.\", SparseEfficiencyWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py:774: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    15735.000000\n",
       "mean         0.099362\n",
       "std          0.037964\n",
       "min          0.020396\n",
       "25%          0.079014\n",
       "50%          0.091450\n",
       "75%          0.108672\n",
       "max          0.688265\n",
       "Name: weight, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To avoid taking the mean including zero, we'll pad it with Nulls. Not the most efficient but works for now \n",
    "transformed_weights[transformed_weights==0] = np.nan\n",
    "\n",
    "# Now transform the objects to the object to the proper format and take the average $tfidf$ score. \n",
    "transformed_weights = pd.DataFrame(transformed_weights.todense())\n",
    "weights = np.asarray(transformed_weights.mean(axis=0)).ravel().tolist()\n",
    "\n",
    "# Make a dataframe and check the statistics of the $tfidf$ score.\n",
    "weights_df = pd.DataFrame({'term': cvec.get_feature_names(), 'weight': weights})\n",
    "weights_df['weight'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "In practice, we usually remove any words with $tfidf$ score less than 0.1. However, depending on your data, one may have to adjust this cut-off slightly. Generally if you have really noisy dataset, you want to reduce this down further \n",
    "\n",
    "From the stat above, I can sufficiently conclude that we have a fairly noisy dataset (median at 50% $tfidf$ = 0.09). But not the end of the world. Lets have a look at what are the top 10 words with lowest $tfidf$ scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3630</th>\n",
       "      <td>dear</td>\n",
       "      <td>0.020396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9550</th>\n",
       "      <td>num1</td>\n",
       "      <td>0.028875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10302</th>\n",
       "      <td>percent1</td>\n",
       "      <td>0.030898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>caps1</td>\n",
       "      <td>0.031495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9414</th>\n",
       "      <td>newspaper</td>\n",
       "      <td>0.032191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8382</th>\n",
       "      <td>location1</td>\n",
       "      <td>0.033617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5754</th>\n",
       "      <td>first</td>\n",
       "      <td>0.036204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>conclusion</td>\n",
       "      <td>0.036350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9555</th>\n",
       "      <td>num2</td>\n",
       "      <td>0.036507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9774</th>\n",
       "      <td>one</td>\n",
       "      <td>0.036938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             term    weight\n",
       "3630         dear  0.020396\n",
       "9550         num1  0.028875\n",
       "10302    percent1  0.030898\n",
       "2065        caps1  0.031495\n",
       "9414    newspaper  0.032191\n",
       "8382    location1  0.033617\n",
       "5754        first  0.036204\n",
       "2915   conclusion  0.036350\n",
       "9555         num2  0.036507\n",
       "9774          one  0.036938"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_df.sort_values(by='weight', ascending=True).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "Notice how it has captured not only stopwords, but also other non-useful words like \"dear\" and \"newspaper\", which is the default opening sentence for all the essays. Now lets have a look at the top 10 words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4021</th>\n",
       "      <td>difrent</td>\n",
       "      <td>0.688265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>compiuters</td>\n",
       "      <td>0.662883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2831</th>\n",
       "      <td>computar</td>\n",
       "      <td>0.623923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7147</th>\n",
       "      <td>illeagle</td>\n",
       "      <td>0.584656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4818</th>\n",
       "      <td>engry</td>\n",
       "      <td>0.573289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10617</th>\n",
       "      <td>pol</td>\n",
       "      <td>0.571404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9310</th>\n",
       "      <td>nede</td>\n",
       "      <td>0.567567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13809</th>\n",
       "      <td>techknowlogy</td>\n",
       "      <td>0.563077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13191</th>\n",
       "      <td>srech</td>\n",
       "      <td>0.551029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>caps33</td>\n",
       "      <td>0.531776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               term    weight\n",
       "4021        difrent  0.688265\n",
       "2772     compiuters  0.662883\n",
       "2831       computar  0.623923\n",
       "7147       illeagle  0.584656\n",
       "4818          engry  0.573289\n",
       "10617           pol  0.571404\n",
       "9310           nede  0.567567\n",
       "13809  techknowlogy  0.563077\n",
       "13191         srech  0.551029\n",
       "2090         caps33  0.531776"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_df.sort_values(by='weight', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "Unlike the R version, there are less spares words appearing with high $tfidf$ scores. In fact, the highly sparse terms have low $tfidf$ score which is what we want. Lets check out some of these spelling mistakes to understand why its getting such a high $tfidf$ score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>weight</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4021</th>\n",
       "      <td>difrent</td>\n",
       "      <td>0.688265</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>compiuters</td>\n",
       "      <td>0.662883</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2831</th>\n",
       "      <td>computar</td>\n",
       "      <td>0.623923</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7147</th>\n",
       "      <td>illeagle</td>\n",
       "      <td>0.584656</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4818</th>\n",
       "      <td>engry</td>\n",
       "      <td>0.573289</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10617</th>\n",
       "      <td>pol</td>\n",
       "      <td>0.571404</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9310</th>\n",
       "      <td>nede</td>\n",
       "      <td>0.567567</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13809</th>\n",
       "      <td>techknowlogy</td>\n",
       "      <td>0.563077</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13191</th>\n",
       "      <td>srech</td>\n",
       "      <td>0.551029</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>caps33</td>\n",
       "      <td>0.531776</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               term    weight  frequency\n",
       "4021        difrent  0.688265          4\n",
       "2772     compiuters  0.662883          9\n",
       "2831       computar  0.623923         10\n",
       "7147       illeagle  0.584656          2\n",
       "4818          engry  0.573289          5\n",
       "10617           pol  0.571404          1\n",
       "9310           nede  0.567567          2\n",
       "13809  techknowlogy  0.563077          8\n",
       "13191         srech  0.551029          3\n",
       "2090         caps33  0.531776         10"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_df.sort_values(by='term', ascending=1)\n",
    "weights_df.sort_values(by='term', ascending=1)\n",
    "combined = pd.concat([weights_df,counts_df['frequency']], axis=1)\n",
    "combined.sort_values(by='weight', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "Turns out these spelling mistake is pretty common amongst students and its confusing the model slightly. We could remove sparse terms, or use bigger dataset or apply spelling correction, all of which may help solve this issue\n",
    "\n",
    "Let's plot the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAIQCAYAAACSb+ZbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f4009237b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# setup the plotting parameters\n",
    "plt.figure(figsize=(12, 9))  \n",
    "ax = plt.subplot(111)  \n",
    "ax.spines[\"top\"].set_visible(False)  \n",
    "ax.spines[\"right\"].set_visible(False)  \n",
    "\n",
    "ax.get_xaxis().tick_bottom()  \n",
    "ax.get_yaxis().tick_left()  \n",
    "plt.xticks(fontsize=14)  \n",
    "plt.yticks(range(5000, 30001, 5000), fontsize=14)  \n",
    "\n",
    "# Plot the histogram of the counts (should be a power-law dist?)\n",
    "plt.hist(combined['weight'],  \n",
    "         color=\"#3F5D7D\", bins=100)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "Plotting the $tfidf$ weight shows a right skew, or in other words a large number of words have low $tfidf$ scores. This makes sense as we intentionally turned off the stopwords and sparewords removal function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtYAAAIMCAYAAADRteuPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAJhAWAMAwATCGgAAJvh/1XbTKAzEa9QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f401122e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 9))  \n",
    "plt.hist(combined['frequency'],  \n",
    "         color=\"#3F5D7D\", bins=100)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "Plotting just the frequencies shows a power law distribution, which again makes sense as we intentionally turned off the stopwords and sparewords removal function. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
